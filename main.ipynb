{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval project \n",
    "**Authors:** Arduini L., Menchini L., Namaki Ghaneh D., Petruzzella C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ir_datasets in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (0.5.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_datasets) (4.12.3)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_datasets) (2.5.0)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_datasets) (5.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_datasets) (2.1.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_datasets) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_datasets) (4.66.5)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_datasets) (2.6)\n",
      "Requirement already satisfied: lz4>=3.1.10 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_datasets) (4.3.3)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_datasets) (0.2.5)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_datasets) (0.2.5)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_datasets) (0.1.9)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_datasets) (3.3.0)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_datasets) (0.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from beautifulsoup4>=4.4.1->ir_datasets) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from requests>=2.22.0->ir_datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from requests>=2.22.0->ir_datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from requests>=2.22.0->ir_datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from requests>=2.22.0->ir_datasets) (2024.8.30)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from trec-car-tools>=2.5.4->ir_datasets) (1.0.0)\n",
      "Requirement already satisfied: nltk in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: ir_measures in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (0.3.3)\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.5 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_measures) (0.5.6)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from ir_measures) (1.0.12)\n",
      "Requirement already satisfied: numpy in /home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages (from cwl-eval>=1.0.10->ir_measures) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ir_datasets\n",
    "!pip install nltk\n",
    "!pip install ir_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "\n",
    "# Load the MS MARCO dataset\n",
    "dataset = ir_datasets.load(\"msmarco-passage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For example, the pressure of electromagnetic radiation on an object derives from the transfer of photon momentum per unit time and unit area to that object, since pressure is force per unit area and force is the change in momentum per unit time.\n"
     ]
    }
   ],
   "source": [
    "# print the first document in the dataset\n",
    "\n",
    "import random\n",
    "\n",
    "# Initialize a flag to check if a document has been printed\n",
    "document_printed = False\n",
    "\n",
    "# Iterate over the documents in the dataset\n",
    "for doc in dataset.docs_iter():\n",
    "    if not document_printed:\n",
    "        if random.random() < 0.01:  # Adjust the probability as needed\n",
    "            print(doc.text)\n",
    "            document_printed = True\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "# Compile regex patterns once globally\n",
    "ACRONYM_REGEX = re.compile(r\"(?<!\\w)\\.(?!\\d)\")\n",
    "PUNCTUATION_TRANS = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "# Preload stopwords set\n",
    "STOPWORDS = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Initialize stemmer\n",
    "STEMMER = nltk.stem.PorterStemmer()\n",
    "\n",
    "def preprocess(s):\n",
    "    # lowercasing\n",
    "    s = s.lower()\n",
    "    \n",
    "    # replace ampersand\n",
    "    s = s.replace(\"&\", \" and \")\n",
    "    \n",
    "    # normalize quotes and dashes\n",
    "    s = s.translate(str.maketrans(\"‘’´“”–-\", \"'''\\\"\\\"--\"))\n",
    "    \n",
    "    # remove unnecessary dots in acronyms (but not decimals)\n",
    "    s = ACRONYM_REGEX.sub(\"\", s)\n",
    "    \n",
    "    # remove punctuation\n",
    "    s = s.translate(PUNCTUATION_TRANS)\n",
    "    \n",
    "    # strip and remove extra spaces\n",
    "    s = \" \".join(s.split())\n",
    "    \n",
    "    # tokenize\n",
    "    tokens = s.split()\n",
    "    \n",
    "    # remove stopwords\n",
    "    tokens = [t for t in tokens if t not in STOPWORDS]\n",
    "    \n",
    "    # stemming\n",
    "    tokens = [STEMMER.stem(t) for t in tokens]\n",
    "    \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def profile(f):\n",
    "    def f_timer(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = f(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        ms = (end - start) * 1000\n",
    "        print(f\"{f.__name__} ({ms:.3f} ms)\")\n",
    "        return result\n",
    "    return f_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aegis/Desktop/ae/esami_in_preparazione/ComputerVision/pratical/mircv_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "@profile\n",
    "def build_index(dataset):\n",
    "    lexicon = {}\n",
    "    doc_index = [] \n",
    "    inv_d, inv_f = {}, {}\n",
    "    termid = 0\n",
    "\n",
    "    num_docs = 0\n",
    "    total_dl = 0\n",
    "    total_toks = 0\n",
    "    for docid, doc in tqdm(enumerate(dataset.docs_iter()), desc='Indexing', total=dataset.docs_count()):\n",
    "        tokens = preprocess(doc.text)\n",
    "        token_tf = Counter(tokens)\n",
    "        for token, tf in token_tf.items():\n",
    "            if token not in lexicon:\n",
    "                lexicon[token] = [termid, 0, 0]\n",
    "                inv_d[termid], inv_f[termid] =  [], []\n",
    "                termid += 1\n",
    "            token_id = lexicon[token][0]\n",
    "            inv_d[token_id].append(docid)\n",
    "            inv_f[token_id].append(tf)\n",
    "            lexicon[token][1] += 1\n",
    "            lexicon[token][2] += tf\n",
    "        doclen = len(tokens)\n",
    "        doc_index.append((str(doc.doc_id), doclen))\n",
    "        total_dl += doclen                         \n",
    "        num_docs += 1\n",
    "        \n",
    "\n",
    "    stats = {\n",
    "        'num_docs': 1 + docid,\n",
    "        'num_terms': len(lexicon),\n",
    "        'num_tokens': total_dl,\n",
    "    }\n",
    "    return lexicon, {'docids': inv_d, 'freqs': inv_f}, doc_index, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress and save the index components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlexicon.pickle.gz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 5\u001b[0m   pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mlex\u001b[49m, f)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minverted_file.pickle.gz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m   pickle\u001b[38;5;241m.\u001b[39mdump(inv, f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lex' is not defined"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "#\n",
    "# check if files exists in the current directory, if not we build the index and we save the files\n",
    "#\n",
    "\n",
    "files_to_check = ['lexicon.pickle.gz', 'inverted_file.pickle.gz', 'document_index.pickle.gz', 'stats.pickle.gz']\n",
    "if all(os.path.exists(file) for file in files_to_check):\n",
    "  print(\"All files already exist.\")\n",
    "  with gzip.open('lexicon.pickle.gz', 'rb') as f:\n",
    "    lex = pickle.load(f)\n",
    "  with gzip.open('inverted_file.pickle.gz', 'rb') as f:\n",
    "    inv = pickle.load(f)\n",
    "  with gzip.open('document_index.pickle.gz', 'rb') as f:\n",
    "    doc = pickle.load(f)\n",
    "  with gzip.open('stats.pickle.gz', 'rb') as f:\n",
    "    stats = pickle.load(f)\n",
    "else:\n",
    "  lex, inv, doc, stats = build_index(dataset)\n",
    "  with gzip.open('lexicon.pickle.gz', 'wb') as f:\n",
    "    pickle.dump(lex, f) \n",
    "  with gzip.open('inverted_file.pickle.gz', 'wb') as f:\n",
    "    pickle.dump(inv, f)\n",
    "  with gzip.open('document_index.pickle.gz', 'wb') as f:\n",
    "    pickle.dump(doc, f)\n",
    "  with gzip.open('stats.pickle.gz', 'wb') as f:\n",
    "    pickle.dump(stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class InvertedIndex:\n",
    "\n",
    "    class PostingListIterator:\n",
    "        def __init__(self, docids, freqs, doc):\n",
    "            self.docids = docids\n",
    "            self.freqs = freqs\n",
    "            self.pos = 0\n",
    "            self.doc = doc\n",
    "\n",
    "        def docid(self):\n",
    "            if self.is_end_list():\n",
    "                return math.inf\n",
    "            return self.docids[self.pos]\n",
    "\n",
    "        def score(self):\n",
    "            if self.is_end_list():\n",
    "                return math.inf\n",
    "            return self.freqs[self.pos]/self.doc[self.docid()][1]\n",
    "\n",
    "        def next(self, target = None):\n",
    "            if not target:\n",
    "                if not self.is_end_list():\n",
    "                    self.pos += 1\n",
    "            else:\n",
    "                if target > self.docid():\n",
    "                    try:\n",
    "                        self.pos = self.docids.index(target, self.pos)\n",
    "                    except ValueError:\n",
    "                        self.pos = len(self.docids)\n",
    "\n",
    "        def is_end_list(self):\n",
    "            return self.pos == len(self.docids)\n",
    "\n",
    "\n",
    "        def len(self):\n",
    "            return len(self.docids)\n",
    "\n",
    "\n",
    "    def __init__(self, lex, inv, doc, stats):\n",
    "        self.lexicon = lex\n",
    "        self.inv = inv\n",
    "        self.doc = doc\n",
    "        self.stat = stats\n",
    "\n",
    "    def num_docs(self):\n",
    "        return self.stats['num_docs']\n",
    "\n",
    "    def get_posting(self, termid):\n",
    "        return InvertedIndex.PostingListIterator(self.inv['docids'][termid], self.inv['freqs'][termid], self.doc)\n",
    "\n",
    "    def get_termids(self, tokens):\n",
    "        return [self.lexicon[token][0] for token in tokens if token in self.lexicon]\n",
    "\n",
    "    def get_postings(self, termids):\n",
    "        return [self.get_posting(termid) for termid in termids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_index = InvertedIndex(lex, inv, doc, stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Query processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompress and load the index components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "with gzip.open('lexicon.pickle.gz', 'rb') as f:\n",
    "    lex = pickle.load(f)\n",
    "with gzip.open('inverted_file.pickle.gz', 'rb') as f:\n",
    "    inv = pickle.load(f)\n",
    "with gzip.open('document_index.pickle.gz', 'rb') as f:\n",
    "    doc = pickle.load(f)\n",
    "with gzip.open('stats.pickle.gz', 'rb') as f:\n",
    "    stats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_dl_2020 = ir_datasets.load(\"msmarco-passage/trec-dl-2020\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranked Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class TopQueue:\n",
    "    def __init__(self, k=10, threshold=0.0):\n",
    "        self.queue = []\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.queue)\n",
    "\n",
    "    def would_enter(self, score):\n",
    "        return score > self.threshold\n",
    "\n",
    "    def clear(self, new_threshold=None):\n",
    "        self.queue = []\n",
    "        if new_threshold:\n",
    "            self.threshold = new_threshold\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<{self.size()} items, th={self.threshold} {self.queue}'\n",
    "\n",
    "    def insert(self, docid, score):\n",
    "        if score > self.threshold:\n",
    "            if self.size() >= self.k:\n",
    "                heapq.heapreplace(self.queue, (score, docid))\n",
    "            else:\n",
    "                heapq.heappush(self.queue, (score, docid))\n",
    "            if self.size() >= self.k:\n",
    "                self.threshold = max(self.threshold, self.queue[0][0])\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM25 scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dl = inv_index.stat['num_tokens'] / inv_index.stat['num_docs']\n",
    "N = inv_index.stat['num_docs']\n",
    "\n",
    "# BM25 for a term\n",
    "def bm25(tf, df, dl, k1=1.5, b=0.75):\n",
    "    idf = math.log(1 + (N - df + 0.5) / (df + 0.5))\n",
    "    term_frequency_component = (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * (dl / avg_dl)))\n",
    "    return idf * term_frequency_component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAAT with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "# Calculate document lengths\n",
    "doc_lengths = defaultdict(int)\n",
    "for docid, doc_len in inv_index.doc:\n",
    "    doc_lengths[docid] = doc_len\n",
    "\n",
    "def min_docid(postings):\n",
    "    min_docid = math.inf\n",
    "    for p in postings:\n",
    "        if not p.is_end_list():\n",
    "            min_docid = min(p.docid(), min_docid)\n",
    "    return min_docid\n",
    "    \n",
    "def daat_bm25(postings, k=10):\n",
    "    top = TopQueue(k)\n",
    "    current_docid = min_docid(postings)\n",
    "\n",
    "    while current_docid != math.inf:\n",
    "        score = 0\n",
    "        next_docid = math.inf\n",
    "\n",
    "        for posting in postings:\n",
    "            if posting.docid() == current_docid:\n",
    "                tf = posting.freqs[posting.pos]\n",
    "                df = posting.len()\n",
    "                dl = doc_lengths[current_docid]\n",
    "\n",
    "                score += bm25(tf, df, dl)\n",
    "\n",
    "                posting.next()\n",
    "            if not posting.is_end_list():\n",
    "                next_docid = min(next_docid, posting.docid())\n",
    "\n",
    "        top.insert(current_docid, score)\n",
    "        current_docid = next_docid\n",
    "\n",
    "    return sorted(top.queue, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAAT with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taat_bm25(postings, k=10):\n",
    "    A = defaultdict(float)\n",
    "\n",
    "    for posting in postings:\n",
    "        current_docid = posting.docid()\n",
    "\n",
    "        df = posting.len()\n",
    "\n",
    "        while current_docid != math.inf:\n",
    "            tf = posting.freqs[posting.pos]\n",
    "            dl = doc_lengths[current_docid]\n",
    "\n",
    "            score = bm25(tf, df, dl)\n",
    "            A[current_docid] += score\n",
    "\n",
    "            posting.next()\n",
    "            current_docid = posting.docid()\n",
    "\n",
    "    top = TopQueue(k)\n",
    "    for docid, score in A.items():\n",
    "        top.insert(docid, score)\n",
    "\n",
    "    return sorted(top.queue, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def query_processing(queries_iter, fn):\n",
    "    res = []\n",
    "    for q in queries_iter:\n",
    "        query = preprocess(q.text)\n",
    "        termids = inv_index.get_termids(query)\n",
    "        postings = inv_index.get_postings(termids)\n",
    "        res.append(fn(postings))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_processing(trec_dl_2020.querires_iter(), daat_bm25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = query_processing(trec_dl_2020.queries_iter(), taat_bm25)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenericDoc(doc_id='1', text='compact memories have flexible capacities  a digital data storage\\nsystem with capacity up to bits and random and or sequential access\\nis described\\n')\n",
      "GenericDoc(doc_id='2', text='an electronic analogue computer for solving systems of linear equations\\nmathematical derivation of the operating principle and stability\\nconditions for a computer consisting of amplifiers\\n')\n",
      "GenericDoc(doc_id='3', text='electronic coordinate transformer  circuit details are given for\\nthe construction of an electronic calculating unit which enables\\nthe polar coordinates of a vector modulus and cosine or sine of the\\nargument to be derived from those of a rectangular system of axes\\n')\n"
     ]
    }
   ],
   "source": [
    "for doc in dataset.docs_iter()[:3]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenericQuery(query_id='1030303', text='who is aziz hashim')\n",
      "GenericQuery(query_id='1037496', text='who is rep scalise?')\n",
      "GenericQuery(query_id='1043135', text='who killed nicholas ii of russia')\n"
     ]
    }
   ],
   "source": [
    "trec_dl_2020 = ir_datasets.load(\"msmarco-passage/trec-dl-2020\")\n",
    "for query in trec_dl_2020.queries_iter()[:3]:\n",
    "    print(query) # namedtuple<query_id, text>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrecQrel(query_id='23849', doc_id='1020327', relevance=2, iteration='0')\n",
      "TrecQrel(query_id='23849', doc_id='1034183', relevance=3, iteration='0')\n",
      "TrecQrel(query_id='23849', doc_id='1120730', relevance=0, iteration='0')\n"
     ]
    }
   ],
   "source": [
    "for ass in list(trec_dl_2020.qrels_iter())[:3]:\n",
    "  print(ass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate run file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m trec_run_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query_id, doc_scores \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresults\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      4\u001b[0m     rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc_id, score \u001b[38;5;129;01min\u001b[39;00m doc_scores:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate run file\n",
    "trec_run_list = []\n",
    "for query_id, doc_scores in results.items():\n",
    "    rank = 1\n",
    "    for doc_id, score in doc_scores:\n",
    "        line = f\"{query_id} Q0 {doc_id} {rank} {score} GOODFELLAS\"\n",
    "        trec_run_list.append(line)\n",
    "        rank += 1\n",
    "\n",
    "with open(\"trec_eval_run_file.txt\", \"w\") as f:\n",
    "    for line in trec_run_list:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create format for Trec_Eval\n",
    "qrels_file = []\n",
    "for qrel in trec_dl_2020.qrels_iter():\n",
    "    line = f\"{qrel.query_id} 0 {qrel.doc_id} {qrel.relevance}\"\n",
    "    qrels_file.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"trec_eval_qrels_file.txt\", \"w\") as f:\n",
    "    for line in qrels_file:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_measures\n",
    "qrels = ir_measures.read_trec_qrels('trec_eval_qrels_file.txt')\n",
    "run = ir_measures.read_trec_run('trec_eval_run_file.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = ir_measures.P@10, ir_measures.R@1000, ir_measures.AP, ir_measures.nDCG@10\n",
    "results = ir_measures.calc_aggregate(measures, qrels, run)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mircv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
